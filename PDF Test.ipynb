{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a1dd0f1-0b73-4861-942c-cfdb8be24dfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install fpdf\n",
    "%pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27e6e1e2-cef3-490c-8263-bd08da5ac953",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from fpdf import FPDF\n",
    "from faker import Faker\n",
    "\n",
    "# Download Indie Flower font if not exists\n",
    "font_url = \"https://github.com/google/fonts/raw/main/ofl/indieflower/IndieFlower-Regular.ttf\"\n",
    "font_path = \"IndieFlower-Regular.ttf\"\n",
    "\n",
    "if not os.path.exists(font_path):\n",
    "    print(\"Downloading Indie Flower font...\")\n",
    "    r = requests.get(font_url)\n",
    "    with open(font_path, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def create_invoice(filename, invoice_num):\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "\n",
    "    # Add the font\n",
    "    pdf.add_font('IndieFlower', '', font_path, uni=True)\n",
    "    pdf.set_font(\"IndieFlower\", size=20)\n",
    "    pdf.cell(200, 12, \"INVOICE\", ln=True, align='C')\n",
    "\n",
    "    pdf.set_font(\"IndieFlower\", size=12)\n",
    "    pdf.cell(200, 10, f\"Invoice Number: {invoice_num}\", ln=True)\n",
    "    pdf.cell(200, 10, f\"Date: {fake.date_this_year()}\", ln=True)\n",
    "    pdf.cell(200, 10, f\"Billed To: {fake.name()}\", ln=True)\n",
    "    pdf.cell(200, 10, f\"Address: {fake.address().replace(chr(10), ', ')}\", ln=True)\n",
    "    for i in range(3):\n",
    "        item = fake.word().capitalize()\n",
    "        price = fake.pyfloat(left_digits=2, right_digits=2, positive=True)\n",
    "        pdf.cell(200, 10, f\"Item {i+1}: {item} - ${price}\", ln=True)\n",
    "    pdf.cell(200, 10, f\"Total Due: ${fake.pyfloat(left_digits=3, right_digits=2, positive=True)}\", ln=True)\n",
    "    pdf.cell(200, 10, \"Thank you for your business!\", ln=True)\n",
    "    pdf.output(filename)\n",
    "\n",
    "output_dir = \"/Volumes/lakeflow_demo/bronze/landing/pdf/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for i in range(3):\n",
    "    create_invoice(os.path.join(output_dir, f\"invoice_{i+1}.pdf\"), f\"INV-2025-{100+i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db55b3aa-b24c-49b9-b34d-08b4bb648757",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import ai_parse_document, from_json, schema_of_json, col, explode\n",
    "\n",
    "# Step 1: Run ai_parse_document and get the JSON string\n",
    "df = (\n",
    "    spark.read.format(\"binaryFile\")\n",
    "    .load(\"/Volumes/lakeflow_demo/bronze/landing/pdf/\")\n",
    "    .withColumn(\"parsed\", ai_parse_document(\"content\"))\n",
    ")\n",
    "\n",
    "# Step 2: Infer schema from a sample row (cast to string)\n",
    "sample_json = str(df.select(\"parsed\").first()[0])\n",
    "json_schema = schema_of_json(sample_json)\n",
    "\n",
    "# Step 3: Parse the JSON string\n",
    "df_parsed = df.withColumn(\n",
    "    \"parsed_json\",\n",
    "    from_json(col(\"parsed\").cast(\"string\"), json_schema)\n",
    ")\n",
    "\n",
    "# Step 4: Explode the document.elements array\n",
    "df_elements = (\n",
    "    df_parsed\n",
    "    .withColumn(\"element\", explode(col(\"parsed_json.document.elements\")))\n",
    "    .select(\n",
    "        col(\"path\").alias(\"file_path\"),\n",
    "        col(\"element.id\").alias(\"element_id\"),\n",
    "        col(\"element.page_id\"),\n",
    "        col(\"element.type\"),\n",
    "        col(\"element.content\")\n",
    "    )\n",
    ")\n",
    "\n",
    "display(df_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bfe920e-2b2a-4a23-b5ce-e555e5561ec0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col, explode, coalesce\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType\n",
    "import re\n",
    "\n",
    "# Parse invoice header (element_id == 1)\n",
    "def parse_invoice_header(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    result = {}\n",
    "    patterns = {\n",
    "        \"invoice_number\": r\"Invoice Number: (.+)\",\n",
    "        \"date\": r\"Date: (.+)\",\n",
    "        \"billed_to\": r\"Billed To: (.+)\",\n",
    "        \"address\": r\"Address: (.+)\"\n",
    "    }\n",
    "    for k, p in patterns.items():\n",
    "        match = re.search(p, text)\n",
    "        result[k] = match.group(1).strip() if match else None\n",
    "    return result\n",
    "\n",
    "header_schema = StructType([\n",
    "    StructField(\"invoice_number\", StringType()),\n",
    "    StructField(\"date\", StringType()),\n",
    "    StructField(\"billed_to\", StringType()),\n",
    "    StructField(\"address\", StringType())\n",
    "])\n",
    "\n",
    "header_udf = udf(parse_invoice_header, header_schema)\n",
    "\n",
    "df_headers = df_elements.filter(col(\"element_id\") == 1) \\\n",
    "    .withColumn(\"header\", header_udf(col(\"content\"))) \\\n",
    "    .select(\"file_path\", col(\"header.*\"))\n",
    "\n",
    "# Parse items and total due from element id 2\n",
    "def parse_markdown_table_with_total(text):\n",
    "    total_due = None\n",
    "    if not text:\n",
    "        return [], None\n",
    "    lines = [line.strip() for line in text.split(\"\\n\") if line.strip()]\n",
    "    header_line = None\n",
    "    for line in lines:\n",
    "        if re.match(r\"\\| *Item *\\| *Description *\\| *.*\\|\", line, re.I):\n",
    "            header_line = line\n",
    "            break\n",
    "    if not header_line:\n",
    "        return [], None\n",
    "    headers = [h.strip() for h in header_line.strip(\"|\").split(\"|\")]\n",
    "    price_index = None\n",
    "    for idx, h in enumerate(headers):\n",
    "        if h.lower() in [\"price\", \"amount\"]:\n",
    "            price_index = idx\n",
    "            break\n",
    "    data_lines = [line for line in lines if line != header_line and not line.startswith(\"|---\")]\n",
    "    items = []\n",
    "    for line in data_lines:\n",
    "        parts = [p.strip() for p in line.strip(\"|\").split(\"|\")]\n",
    "        if len(parts) == len(headers):\n",
    "            if parts[0].lower() == \"total due\":\n",
    "                total_due = parts[price_index].replace(\"$\", \"\").strip()\n",
    "            else:\n",
    "                price_value = parts[price_index].replace(\"$\", \"\").strip()\n",
    "                # Extract digits only from item field (remove words like \"Item\")\n",
    "                item_number = re.search(r\"\\d+\", parts[0])\n",
    "                item_number = item_number.group() if item_number else parts[0]\n",
    "                items.append({\n",
    "                    \"item\": item_number,\n",
    "                    \"description\": parts[1],\n",
    "                    \"price\": price_value\n",
    "                })\n",
    "    return items, total_due\n",
    "\n",
    "item_schema = ArrayType(\n",
    "    StructType([\n",
    "        StructField(\"item\", StringType()),\n",
    "        StructField(\"description\", StringType()),\n",
    "        StructField(\"price\", StringType())\n",
    "    ])\n",
    ")\n",
    "\n",
    "result_schema = StructType([\n",
    "    StructField(\"items\", item_schema),\n",
    "    StructField(\"total_due\", StringType())\n",
    "])\n",
    "\n",
    "table_udf = udf(parse_markdown_table_with_total, result_schema)\n",
    "\n",
    "df_table_parsed = df_elements.filter(col(\"element_id\") == 2) \\\n",
    "    .withColumn(\"parsed\", table_udf(col(\"content\")))\n",
    "\n",
    "df_items = df_table_parsed.select(\n",
    "    \"file_path\",\n",
    "    explode(col(\"parsed.items\")).alias(\"item_struct\"),\n",
    "    col(\"parsed.total_due\")\n",
    ").select(\n",
    "    \"file_path\",\n",
    "    col(\"item_struct.item\").alias(\"item\"),\n",
    "    col(\"item_struct.description\"),\n",
    "    col(\"item_struct.price\"),\n",
    "    col(\"total_due\")\n",
    ")\n",
    "\n",
    "# Extract total due separately from element id 3 (if present)\n",
    "df_total_due = df_elements.filter(col(\"element_id\") == 3) \\\n",
    "    .select(\"file_path\", col(\"content\"))\n",
    "\n",
    "def extract_total_due(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    m = re.search(r\"Total Due: \\$?([\\d\\.]+)\", text)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "extract_total_due_udf = udf(extract_total_due, StringType())\n",
    "\n",
    "df_total_due = df_total_due.withColumn(\"total_due_3\", extract_total_due_udf(col(\"content\")))\n",
    "\n",
    "# Join items with headers on file_path to get header metadata per item row\n",
    "df_item_header = df_items.join(df_headers, on=\"file_path\", how=\"left\")\n",
    "\n",
    "# Join totalDue from element 3, prioritize it if present\n",
    "df_final = df_item_header.join(df_total_due.select(\"file_path\", \"total_due_3\"), on=\"file_path\", how=\"left\") \\\n",
    "    .withColumn(\"final_total_due\", coalesce(col(\"total_due_3\"), col(\"total_due\"))) \\\n",
    "    .drop(\"total_due_3\", \"total_due\")\n",
    "\n",
    "# Select desired columns for display\n",
    "df_final_display = df_final.select(\n",
    "    \"invoice_number\",\n",
    "    \"date\",\n",
    "    \"billed_to\",\n",
    "    \"address\",\n",
    "    \"item\",\n",
    "    \"description\",\n",
    "    \"price\",\n",
    "    \"final_total_due\"\n",
    ")\n",
    "\n",
    "display(df_final_display)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "PDF Test",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
